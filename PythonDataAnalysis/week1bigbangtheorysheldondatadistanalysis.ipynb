{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00aead0",
   "metadata": {},
   "source": [
    "# Scientific Numbers Inspired by The Big Bang Theory: A Data Analysis\n",
    "In this project, we analyze a set of scientific numbers inspired by the TV show *The Big Bang Theory*. The aim is to explore the distribution of these numbers and identify which statistical distributions they most resemble. \n",
    "We'll use several well-known statistical tests to determine how well different distributions (like normal, log-normal, exponential, and gamma) fit this data.\n",
    "\n",
    "This project is not just about code but also aims to explore how various statistical models behave when applied to real-world scientific constants, which are key to understanding the universe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri içe aktarıyoruz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# The Big Bang Theory temalı bilimsel sayılar\n",
    "big_bang_theory_numbers = [\n",
    "    13.8,                # Evrenin yaşı (milyar yıl)\n",
    "    2.725,               # Kozmik mikrodalga arka plan ısısı (Kelvin)\n",
    "    6.626e-34,           # Planck sabiti (Joule*second)\n",
    "    299792458,           # Işık hızı (m/s)\n",
    "    9.81,                # Yerçekimi ivmesi (m/s^2)\n",
    "    1.602e-19,           # Elektron yükü (Coulomb)\n",
    "    1.380649e-23,        # Boltzmann sabiti (Joule/Kelvin)\n",
    "    6.02214076e23,       # Avogadro sayısı (1/mol)\n",
    "    3.1415926535,        # Pi sayısı\n",
    "    2.99792458e8,        # Işık hızı (m/s)\n",
    "    1.6726219e-27,       # Proton kütlesi (kg)\n",
    "    9.10938356e-31,      # Elektron kütlesi (kg)\n",
    "    8.314462618,         # Gaz sabiti (Joule/(mol*K))\n",
    "    5.670374419e-8,      # Stefan-Boltzmann sabiti (W/(m^2*K^4))\n",
    "    6.67430e-11,         # Evrensel çekim sabiti (m^3/(kg*s^2))\n",
    "    1.25663706212e-6,    # Manyetik alan sabiti (N/A^2)\n",
    "    8.9875517923e9,      # Coulomb sabiti (N*m^2/C^2)\n",
    "    273.15,              # Suyun donma noktası (Kelvin)\n",
    "    5.9722e24,           # Dünya'nın kütlesi (kg)\n",
    "    1.989e30             # Güneş'in kütlesi (kg)\n",
    "]\n",
    "\n",
    "# Diziyi numpy array'e çeviriyoruz\n",
    "data = np.array(big_bang_theory_numbers)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035762b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics\n",
    "print(\"Basic Statistics:\")\n",
    "print(f\"Mean: {np.mean(data):.2e}\")\n",
    "print(f\"Median: {np.median(data):.2e}\")\n",
    "print(f\"Standard Deviation: {np.std(data):.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logaritmik ölçekte histogram oluşturma\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bin sayısını belirleyin\n",
    "num_bins = 20  # İhtiyacınıza göre bu sayıyı değiştirebilirsiniz\n",
    "\n",
    "# Veri aralığının logaritmasını hesaplayın\n",
    "log_min = np.log10(data.min())\n",
    "log_max = np.log10(data.max())\n",
    "\n",
    "# Logaritmik olarak eşit aralıklı binler oluşturun\n",
    "bins = np.logspace(log_min, log_max, num_bins)\n",
    "\n",
    "# Histogramı çizdirin\n",
    "plt.hist(data, bins=bins, edgecolor='black')\n",
    "plt.title('Bilimsel Sayıların Dağılımı')\n",
    "plt.xlabel('Değerler (logaritmik ölçek)')\n",
    "plt.ylabel('Frekans')\n",
    "plt.xscale('log')  # x eksenini logaritmik ölçeğe ayarla\n",
    "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dağılım analizi için verileri logaritmik olarak dönüştürelim\n",
    "log_data = np.log(data)\n",
    "\n",
    "# Dağılım analizi\n",
    "distributions = [\n",
    "    ('Normal', stats.norm),\n",
    "    ('Log-normal', stats.lognorm),\n",
    "    ('Exponential', stats.expon),\n",
    "    ('Gamma', stats.gamma)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, distribution in distributions:\n",
    "    # Dağılım parametrelerini tahmin et\n",
    "    if name == 'Log-normal':\n",
    "        # Log-normal dağılımı için özel işlem\n",
    "        shape, loc, scale = distribution.fit(data, floc=0)\n",
    "        params = (shape, loc, scale)\n",
    "        # K-S testi için CDF fonksiyonunu tanımla\n",
    "        cdf = lambda x: distribution.cdf(x, *params)\n",
    "    else:\n",
    "        # Diğer dağılımlar için\n",
    "        params = distribution.fit(log_data)\n",
    "        # K-S testi için CDF fonksiyonunu tanımla\n",
    "        cdf = lambda x: distribution.cdf(np.log(x), *params)\n",
    "    \n",
    "    # Kolmogorov-Smirnov testi uygula\n",
    "    D, p_value = stats.kstest(data, cdf)\n",
    "    \n",
    "    # Benzerlik oranını hesapla (1 - D istatistiği)\n",
    "    similarity = 1 - D\n",
    "    \n",
    "    results.append((name, similarity, p_value))\n",
    "\n",
    "# Sonuçları benzerlik oranına göre sırala\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nDağılım Analizi Sonuçları:\")\n",
    "for name, similarity, p_value in results:\n",
    "    print(f\"{name} Dağılımı:\")\n",
    "    print(f\"  Benzerlik Oranı: {similarity:.2%}\")\n",
    "    print(f\"  p-değeri: {p_value:.4e}\")\n",
    "    if p_value > 0.05:\n",
    "        print(\"  Veriler bu dağılıma uyuyor olabilir.\")\n",
    "    else:\n",
    "        print(\"  Veriler bu dağılıma uymama eğiliminde.\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f75f08",
   "metadata": {},
   "source": [
    "## Results and Analysis\n",
    "After running the analysis, we compared the data to multiple statistical distributions (Normal, Log-normal, Exponential, and Gamma) using the Kolmogorov-Smirnov test. This test evaluates how closely the data matches each distribution, giving us a sense of which model best fits our scientific constants.\n",
    "\n",
    "### Observations:\n",
    "- **Normal Distribution**: When we applied a logarithmic transformation to the data, it closely resembled a normal distribution. This suggests that after accounting for the wide range in magnitudes (due to the scientific nature of the data), the values are normally distributed.\n",
    "  \n",
    "- **Log-normal Distribution**: Without any transformations, the original dataset shows some resemblance to a log-normal distribution. Given that many natural and scientific phenomena (like income distribution or biological growth rates) follow log-normal distributions, this makes sense.\n",
    "\n",
    "- **Exponential and Gamma Distributions**: These distributions were less fitting for the dataset. While exponential and gamma models often describe time between events or life spans of particles, they don't seem to capture the behavior of these scientific constants well.\n",
    "\n",
    "### Why This Matters:\n",
    "Understanding the distribution of such scientifically significant numbers allows us to explore deeper patterns in the universe. Many constants in physics arise from underlying statistical laws, and recognizing their distribution helps scientists develop more accurate models of reality. The fit with the log-normal and normal distributions, in particular, is a compelling finding since many universal phenomena, when viewed on a logarithmic scale, exhibit normal-like behavior.\n",
    "\n",
    "### Conclusion:\n",
    "While the dataset doesn't perfectly match any single distribution, the closest fits were observed with the normal and log-normal models. These findings align with the notion that many large-scale scientific values, once logarithmically transformed, tend to fall into familiar statistical patterns.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}